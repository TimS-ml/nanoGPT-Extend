{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Visualization for Encoder-Decoder Transformer\n",
    "\n",
    "This notebook provides visualization tools for understanding attention patterns in the Encoder-Decoder Transformer model.\n",
    "\n",
    "Visualizations include:\n",
    "- Encoder self-attention\n",
    "- Decoder self-attention (causal)\n",
    "- Decoder source attention (cross-attention)\n",
    "\n",
    "Requires: `altair`, `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Enable altair to handle more than 5000 rows\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer import make_model, greedy_decode\n",
    "from src.shared.training import Batch\n",
    "\n",
    "# Create a small model for demonstration\n",
    "# In practice, load a trained model\n",
    "V = 11  # Vocabulary size for copy task\n",
    "model = make_model(V, V, N=2, d_model=128, h=4)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtx2df(m, max_row, max_col, row_tokens, col_tokens):\n",
    "    \"\"\"\n",
    "    Convert a dense attention matrix to a DataFrame for visualization.\n",
    "    \n",
    "    Args:\n",
    "        m: Attention matrix (seq_len x seq_len)\n",
    "        max_row: Maximum rows to include\n",
    "        max_col: Maximum columns to include\n",
    "        row_tokens: List of row token labels\n",
    "        col_tokens: List of column token labels\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with row, column, value, and token labels\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r,\n",
    "                c,\n",
    "                float(m[r, c]),\n",
    "                f\"{r:03d} {row_tokens[r] if len(row_tokens) > r else '<blank>'}\",\n",
    "                f\"{c:03d} {col_tokens[c] if len(col_tokens) > c else '<blank>'}\",\n",
    "            )\n",
    "            for r in range(m.shape[0])\n",
    "            for c in range(m.shape[1])\n",
    "            if r < max_row and c < max_col\n",
    "        ],\n",
    "        columns=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def attn_map(attn, layer, head, row_tokens, col_tokens, max_dim=30):\n",
    "    \"\"\"\n",
    "    Create an altair heatmap for attention visualization.\n",
    "    \n",
    "    Args:\n",
    "        attn: Attention tensor (batch, heads, seq, seq)\n",
    "        layer: Layer index (for title)\n",
    "        head: Head index to visualize\n",
    "        row_tokens: Row (query) token labels\n",
    "        col_tokens: Column (key) token labels\n",
    "        max_dim: Maximum dimension to display\n",
    "    \n",
    "    Returns:\n",
    "        Altair Chart object\n",
    "    \"\"\"\n",
    "    df = mtx2df(\n",
    "        attn[0, head].data,\n",
    "        max_dim,\n",
    "        max_dim,\n",
    "        row_tokens,\n",
    "        col_tokens,\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(data=df)\n",
    "        .mark_rect()\n",
    "        .encode(\n",
    "            x=alt.X(\"col_token\", axis=alt.Axis(title=\"Key\")),\n",
    "            y=alt.Y(\"row_token\", axis=alt.Axis(title=\"Query\")),\n",
    "            color=alt.Color(\"value:Q\", scale=alt.Scale(scheme=\"viridis\")),\n",
    "            tooltip=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "        )\n",
    "        .properties(height=400, width=400, title=f\"Head {head}\")\n",
    "        .interactive()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder_attn(model, layer):\n",
    "    \"\"\"Get encoder self-attention weights from a layer.\"\"\"\n",
    "    return model.encoder.layers[layer].self_attn.attn\n",
    "\n",
    "\n",
    "def get_decoder_self_attn(model, layer):\n",
    "    \"\"\"Get decoder self-attention weights from a layer.\"\"\"\n",
    "    return model.decoder.layers[layer].self_attn.attn\n",
    "\n",
    "\n",
    "def get_decoder_src_attn(model, layer):\n",
    "    \"\"\"Get decoder source (cross) attention weights from a layer.\"\"\"\n",
    "    return model.decoder.layers[layer].src_attn.attn\n",
    "\n",
    "\n",
    "def visualize_layer(model, layer, getter_fn, ntokens, row_tokens, col_tokens):\n",
    "    \"\"\"\n",
    "    Visualize attention patterns for all heads in a layer.\n",
    "    \n",
    "    Args:\n",
    "        model: The transformer model\n",
    "        layer: Layer index\n",
    "        getter_fn: Function to get attention weights\n",
    "        ntokens: Number of tokens\n",
    "        row_tokens: Query token labels\n",
    "        col_tokens: Key token labels\n",
    "    \n",
    "    Returns:\n",
    "        Altair Chart with all heads\n",
    "    \"\"\"\n",
    "    attn = getter_fn(model, layer)\n",
    "    n_heads = attn.shape[1]\n",
    "    \n",
    "    charts = [\n",
    "        attn_map(\n",
    "            attn,\n",
    "            layer,\n",
    "            h,\n",
    "            row_tokens=row_tokens,\n",
    "            col_tokens=col_tokens,\n",
    "            max_dim=ntokens,\n",
    "        )\n",
    "        for h in range(n_heads)\n",
    "    ]\n",
    "    \n",
    "    # Arrange heads in a grid (2 columns)\n",
    "    rows = []\n",
    "    for i in range(0, len(charts), 2):\n",
    "        if i + 1 < len(charts):\n",
    "            rows.append(charts[i] | charts[i + 1])\n",
    "        else:\n",
    "            rows.append(charts[i])\n",
    "    \n",
    "    result = rows[0]\n",
    "    for row in rows[1:]:\n",
    "        result = result & row\n",
    "    \n",
    "    return result.properties(title=f\"Layer {layer + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Forward Pass to Capture Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer.attention import subsequent_mask\n",
    "\n",
    "# Create sample input (copy task)\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "src_mask = torch.ones(1, 1, src.size(1))\n",
    "\n",
    "# Encode source\n",
    "memory = model.encode(src, src_mask)\n",
    "\n",
    "# Create target (for teacher forcing visualization)\n",
    "tgt = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "tgt_mask = subsequent_mask(tgt.size(1))\n",
    "\n",
    "# Decode\n",
    "out = model.decode(memory, src_mask, tgt, tgt_mask)\n",
    "\n",
    "# Token labels for visualization\n",
    "src_tokens = [f\"src_{i}\" for i in range(src.size(1))]\n",
    "tgt_tokens = [f\"tgt_{i}\" for i in range(tgt.size(1))]\n",
    "\n",
    "print(f\"Source shape: {src.shape}\")\n",
    "print(f\"Target shape: {tgt.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Self-Attention\n",
    "\n",
    "The encoder uses bidirectional self-attention - each position can attend to all other positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize encoder self-attention for layer 0\n",
    "visualize_layer(\n",
    "    model,\n",
    "    layer=0,\n",
    "    getter_fn=get_encoder_attn,\n",
    "    ntokens=len(src_tokens),\n",
    "    row_tokens=src_tokens,\n",
    "    col_tokens=src_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize encoder self-attention for layer 1\n",
    "visualize_layer(\n",
    "    model,\n",
    "    layer=1,\n",
    "    getter_fn=get_encoder_attn,\n",
    "    ntokens=len(src_tokens),\n",
    "    row_tokens=src_tokens,\n",
    "    col_tokens=src_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Self-Attention (Causal)\n",
    "\n",
    "The decoder uses causal (masked) self-attention - each position can only attend to previous positions and itself. This preserves the autoregressive property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decoder self-attention for layer 0\n",
    "visualize_layer(\n",
    "    model,\n",
    "    layer=0,\n",
    "    getter_fn=get_decoder_self_attn,\n",
    "    ntokens=len(tgt_tokens),\n",
    "    row_tokens=tgt_tokens,\n",
    "    col_tokens=tgt_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decoder self-attention for layer 1\n",
    "visualize_layer(\n",
    "    model,\n",
    "    layer=1,\n",
    "    getter_fn=get_decoder_self_attn,\n",
    "    ntokens=len(tgt_tokens),\n",
    "    row_tokens=tgt_tokens,\n",
    "    col_tokens=tgt_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Source Attention (Cross-Attention)\n",
    "\n",
    "The decoder's cross-attention allows each target position to attend to all source positions. This is how the decoder \"reads\" the encoded source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decoder source attention for layer 0\n",
    "visualize_layer(\n",
    "    model,\n",
    "    layer=0,\n",
    "    getter_fn=get_decoder_src_attn,\n",
    "    ntokens=max(len(src_tokens), len(tgt_tokens)),\n",
    "    row_tokens=tgt_tokens,\n",
    "    col_tokens=src_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decoder source attention for layer 1\n",
    "visualize_layer(\n",
    "    model,\n",
    "    layer=1,\n",
    "    getter_fn=get_decoder_src_attn,\n",
    "    ntokens=max(len(src_tokens), len(tgt_tokens)),\n",
    "    row_tokens=tgt_tokens,\n",
    "    col_tokens=src_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsequent Mask Visualization\n",
    "\n",
    "This shows the causal mask used in decoder self-attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_subsequent_mask(size=20):\n",
    "    \"\"\"Visualize the subsequent (causal) mask.\"\"\"\n",
    "    mask = subsequent_mask(size)\n",
    "    \n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Subsequent Mask\": mask[0][x, y].flatten().float(),\n",
    "                    \"Position (Key)\": y,\n",
    "                    \"Position (Query)\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(size)\n",
    "            for x in range(size)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_rect()\n",
    "        .properties(height=400, width=400, title=\"Causal (Subsequent) Mask\")\n",
    "        .encode(\n",
    "            alt.X(\"Position (Key):O\"),\n",
    "            alt.Y(\"Position (Query):O\"),\n",
    "            alt.Color(\n",
    "                \"Subsequent Mask:Q\",\n",
    "                scale=alt.Scale(scheme=\"viridis\"),\n",
    "                legend=alt.Legend(title=\"Can Attend\")\n",
    "            ),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "visualize_subsequent_mask(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformer.embeddings import PositionalEncoding\n",
    "\n",
    "def visualize_positional_encoding(d_model=64, max_len=100, dims_to_show=None):\n",
    "    \"\"\"Visualize positional encoding patterns.\"\"\"\n",
    "    if dims_to_show is None:\n",
    "        dims_to_show = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "    \n",
    "    pe = PositionalEncoding(d_model, dropout=0)\n",
    "    y = pe.forward(torch.zeros(1, max_len, d_model))\n",
    "    \n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Encoding Value\": y[0, :, dim].detach().numpy(),\n",
    "                    \"Dimension\": f\"dim_{dim}\",\n",
    "                    \"Position\": list(range(max_len)),\n",
    "                }\n",
    "            )\n",
    "            for dim in dims_to_show\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_line()\n",
    "        .properties(width=800, height=300, title=\"Sinusoidal Positional Encodings\")\n",
    "        .encode(\n",
    "            x=alt.X(\"Position:Q\"),\n",
    "            y=alt.Y(\"Encoding Value:Q\"),\n",
    "            color=alt.Color(\"Dimension:N\"),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "visualize_positional_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Schedule Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.shared.lr_scheduler import rate\n",
    "\n",
    "def visualize_lr_schedule():\n",
    "    \"\"\"Visualize the Noam learning rate schedule.\"\"\"\n",
    "    configs = [\n",
    "        (512, 1, 4000, \"d_model=512, warmup=4000\"),\n",
    "        (512, 1, 8000, \"d_model=512, warmup=8000\"),\n",
    "        (256, 1, 4000, \"d_model=256, warmup=4000\"),\n",
    "    ]\n",
    "    \n",
    "    max_steps = 20000\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Learning Rate\": [rate(step, d_model, factor, warmup) for step in range(max_steps)],\n",
    "                    \"Configuration\": config_name,\n",
    "                    \"Step\": list(range(max_steps)),\n",
    "                }\n",
    "            )\n",
    "            for d_model, factor, warmup, config_name in configs\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_line()\n",
    "        .properties(width=600, height=300, title=\"Noam Learning Rate Schedule\")\n",
    "        .encode(\n",
    "            x=alt.X(\"Step:Q\"),\n",
    "            y=alt.Y(\"Learning Rate:Q\"),\n",
    "            color=alt.Color(\"Configuration:N\"),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "visualize_lr_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Smoothing Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.shared.loss import LabelSmoothing\n",
    "\n",
    "def visualize_label_smoothing(vocab_size=5, smoothing=0.4):\n",
    "    \"\"\"Visualize the label smoothing distribution.\"\"\"\n",
    "    crit = LabelSmoothing(vocab_size, padding_idx=0, smoothing=smoothing)\n",
    "    \n",
    "    # Dummy predictions\n",
    "    predict = torch.FloatTensor(\n",
    "        [\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Compute loss to populate true_dist\n",
    "    crit(predict.log(), torch.LongTensor([2, 1, 0, 3, 3]))\n",
    "    \n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Target Distribution\": crit.true_dist[x, y].flatten(),\n",
    "                    \"Vocabulary Index\": y,\n",
    "                    \"Example\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(vocab_size)\n",
    "            for x in range(5)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_rect()\n",
    "        .properties(\n",
    "            height=200,\n",
    "            width=200,\n",
    "            title=f\"Label Smoothing (smoothing={smoothing})\"\n",
    "        )\n",
    "        .encode(\n",
    "            alt.X(\"Vocabulary Index:O\", title=\"Vocab Index\"),\n",
    "            alt.Y(\"Example:O\", title=\"Example\"),\n",
    "            alt.Color(\n",
    "                \"Target Distribution:Q\",\n",
    "                scale=alt.Scale(scheme=\"viridis\")\n",
    "            ),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "visualize_label_smoothing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
